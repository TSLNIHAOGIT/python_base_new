{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls ../../cloze_answer\n",
    "# !pip install xlrd -i https://pypi.douban.com/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import choice\n",
    "from keras_bert import load_trained_model_from_checkpoint, Tokenizer\n",
    "import re, os\n",
    "import codecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100\n",
    "config_path = '../../cloze_answer/chinese_L-12_H-768_A-12/bert_config.json'\n",
    "checkpoint_path = '../../cloze_answer/chinese_L-12_H-768_A-12/bert_model.ckpt'\n",
    "dict_path = '../../cloze_answer/chinese_L-12_H-768_A-12/vocab.txt'\n",
    "\n",
    "\n",
    "token_dict = {}\n",
    "\n",
    "with codecs.open(dict_path, 'r', 'utf8') as reader:\n",
    "    for line in reader:\n",
    "        token = line.strip()\n",
    "        token_dict[token] = len(token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 13503),\n",
       " ('秋', 4904),\n",
       " ('##映', 16273),\n",
       " ('##29', 8887),\n",
       " ('苛', 5729),\n",
       " ('##穫', 18010),\n",
       " ('##麩', 20989),\n",
       " ('##卮', 14368),\n",
       " ('##玄', 17428),\n",
       " ('ᄂ', 290)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(token_dict.items())[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_dict['''[PAD]''']##原始pad对应0，直接使用预训练模型，pad也要对应0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_dict['''[UNK]''']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_dict['''[unused1]''']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UNK] 100\n",
      "[CLS] 101\n",
      "[SEP] 102\n",
      "[MASK] 103\n"
     ]
    }
   ],
   "source": [
    "for each in ['''[UNK]''','''[CLS]''','''[SEP]''','''[MASK]''']:\n",
    "    print(each,token_dict[each])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurTokenizer(Tokenizer):\n",
    "    def _tokenize(self, text):\n",
    "        R = []\n",
    "        for c in text:\n",
    "            if c in self._token_dict:\n",
    "                R.append(c)\n",
    "            elif self._is_space(c):\n",
    "                R.append('[unused1]') # space类用未经训练的[unused1]表示\n",
    "            else:\n",
    "                R.append('[UNK]') # 剩余的字符是[UNK]\n",
    "        return R\n",
    "\n",
    "tokenizer = OurTokenizer(token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([101,\n",
       "  691,\n",
       "  6205,\n",
       "  679,\n",
       "  7231,\n",
       "  8024,\n",
       "  1545,\n",
       "  1400,\n",
       "  1922,\n",
       "  2345,\n",
       "  8024,\n",
       "  2128,\n",
       "  6163,\n",
       "  671,\n",
       "  702,\n",
       "  4178,\n",
       "  3717,\n",
       "  1690,\n",
       "  8230,\n",
       "  1779,\n",
       "  7178,\n",
       "  8024,\n",
       "  1008,\n",
       "  6413,\n",
       "  1408,\n",
       "  8043,\n",
       "  7178,\n",
       "  5314,\n",
       "  2130,\n",
       "  749,\n",
       "  1355,\n",
       "  4385,\n",
       "  6158,\n",
       "  7946,\n",
       "  749,\n",
       "  8013,\n",
       "  102],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tokenizer(token_dict).encode(first='东西不错，售后太差，安装一个热水器400块钱，像话吗？钱给完了发现被黑了！')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " '东',\n",
       " '西',\n",
       " '龘',\n",
       " '尕',\n",
       " '尕',\n",
       " '，',\n",
       " '售',\n",
       " '后',\n",
       " '太',\n",
       " '差',\n",
       " '，',\n",
       " '安',\n",
       " '装',\n",
       " '一',\n",
       " '个',\n",
       " '热',\n",
       " '水',\n",
       " '器',\n",
       " '400',\n",
       " '块',\n",
       " '钱',\n",
       " '，',\n",
       " '像',\n",
       " '话',\n",
       " '吗',\n",
       " '？',\n",
       " '钱',\n",
       " '给',\n",
       " '完',\n",
       " '了',\n",
       " '发',\n",
       " '现',\n",
       " '被',\n",
       " '黑',\n",
       " '了',\n",
       " '！',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##bert自带的分词方式\n",
    "Tokenizer(token_dict).tokenize(first='东西龘尕尕，售后 太差，安装一个热水器400块钱，像话吗？钱给完了发现被黑了！')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " '东',\n",
       " '西',\n",
       " '[UNK]',\n",
       " '尕',\n",
       " '尕',\n",
       " '，',\n",
       " '售',\n",
       " '后',\n",
       " '[unused1]',\n",
       " '太',\n",
       " '差',\n",
       " '，',\n",
       " '安',\n",
       " '装',\n",
       " '一',\n",
       " '个',\n",
       " '热',\n",
       " '水',\n",
       " '器',\n",
       " '4',\n",
       " '0',\n",
       " '0',\n",
       " '块',\n",
       " '钱',\n",
       " '，',\n",
       " '像',\n",
       " '话',\n",
       " '吗',\n",
       " '？',\n",
       " '钱',\n",
       " '给',\n",
       " '完',\n",
       " '了',\n",
       " '发',\n",
       " '现',\n",
       " '被',\n",
       " '黑',\n",
       " '了',\n",
       " '！',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(first='东西龘尕尕，售后 太差，安装一个热水器400块钱，像话吗？钱给完了发现被黑了！')\n",
    "##做了修改对应在训练语料中没有出现的词用[unk]代替，空格用[unused1]代替"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices=[101, 691, 6205, 679, 7231, 8024, 1545, 1400, 1922, 2345, 8024, 2128, 6163, 671, 702, 4178, 3717, 1690, 125, 121, 121, 1779, 7178, 8024, 1008, 6413, 1408, 8043, 7178, 5314, 2130, 749, 1355, 4385, 6158, 7946, 749, 8013, 102] \n",
      " segments=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "indices, segments = tokenizer.encode(first='东西不错，售后太差，安装一个热水器400块钱，像话吗？钱给完了发现被黑了！')\n",
    "print('indices={}'.format(indices),'\\n','segments={}'.format(segments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg.xls  pos.xls  sent_classifier.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = pd.read_excel('neg.xls', header=None)\n",
    "pos = pd.read_excel('pos.xls', header=None)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>做为一本声名在外的流行书，说的还是广州的外企，按道理应该和我的生存环境差不多啊。但是一看之下...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>作者有明显的自恋倾向，只有有老公养不上班的太太们才能像她那样生活。很多方法都不实用，还有抄袭...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>作者完全是以一个过来的自认为是成功者的角度去写这个问题，感觉很不客观。虽然不是很喜欢，但是，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>作者提倡内调，不信任化妆品，这点赞同。但是所列举的方法太麻烦，配料也不好找。不是太实用。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>作者的文笔一般，观点也是和市面上的同类书大同小异，不推荐读者购买。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  做为一本声名在外的流行书，说的还是广州的外企，按道理应该和我的生存环境差不多啊。但是一看之下...\n",
       "1  作者有明显的自恋倾向，只有有老公养不上班的太太们才能像她那样生活。很多方法都不实用，还有抄袭...\n",
       "2  作者完全是以一个过来的自认为是成功者的角度去写这个问题，感觉很不客观。虽然不是很喜欢，但是，...\n",
       "3       作者提倡内调，不信任化妆品，这点赞同。但是所列举的方法太麻烦，配料也不好找。不是太实用。\n",
       "4                  作者的文笔一般，观点也是和市面上的同类书大同小异，不推荐读者购买。"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        做为一本声名在外的流行书，说的还是广州的外企，按道理应该和我的生存环境差不多啊。但是一看之下...\n",
       "1        作者有明显的自恋倾向，只有有老公养不上班的太太们才能像她那样生活。很多方法都不实用，还有抄袭...\n",
       "2        作者完全是以一个过来的自认为是成功者的角度去写这个问题，感觉很不客观。虽然不是很喜欢，但是，...\n",
       "3             作者提倡内调，不信任化妆品，这点赞同。但是所列举的方法太麻烦，配料也不好找。不是太实用。\n",
       "4                        作者的文笔一般，观点也是和市面上的同类书大同小异，不推荐读者购买。\n",
       "5        作者的文笔还行，但通篇感觉太琐碎，有点文人的无病呻吟。自由主义者。作者的品性不敢苟同，无民族...\n",
       "6                            作者倒是个很小资的人,但有点自恋的感觉,书并没有什么大帮助\n",
       "7        作为一本描写过去年代感情生活的小说，作者明显生活经验不足，并且文字功底极其一般，看后感觉浪费...\n",
       "8        作为个人经验在网上谈谈可以，但拿来出书就有点过了，书中还有些明显的谬误。不过文笔还不错，建议...\n",
       "9        昨天刚兴奋地写了评论,今天便遇一闹心事,因把此套书推荐给很多朋友,朋友就拖我在网上购,结果前...\n",
       "10                              昨天打开书才翻了几页，书页纷纷掉落了，请问怎么回事？\n",
       "11       最近下单号为：1442083355，其中一套书《易经的智慧》当当网  少带光盘 。为了得到解...\n",
       "12                                     最大的缺陷是容易诱导养成中文式英语习惯\n",
       "13                        最大的困扰是穴位有点把不准，不过我牢记中里先生离穴不离经的教诲。\n",
       "14       最大的不好就是没有音标，看的时候不是很方便，而且书的内容一点也不好笑，或者说作者幽默感很有限。。。\n",
       "15       纵观整部书（上下两册）  从文字，到结构，人物，情节 没有一个地方是可取的虽然有过从业经验 ...\n",
       "16                    总结一下，女人要现实。要么嫁好老公，要么抓住机遇有事业……这还用她说啊。\n",
       "17                        总共买了8本书，其它都还好，这本书感觉旧旧的，也没什么心情去看了\n",
       "18                                    总的来说有点乱七八糟的感觉。重复又重复。\n",
       "19                                    总的来说有点乱七八糟的感觉。重复又重复。\n",
       "20                                    总的感觉前言不搭后语，浪费了银子，呜呜。\n",
       "21                                    总的感觉前言不搭后语，浪费了银子，呜呜。\n",
       "22          字太小,躺着看时太累.关于吃的篇幅很多.我也一个人住,才不愿意花那么多时间自己在家折腾吃的.\n",
       "23                     字太少了，一页只有几个字，内容不够丰富，适合二岁以下的孩子看，而且太贵\n",
       "24       字很大,内容不够充实当初看大家评论说得很好才买的但实际上却没那么好,感觉深度也不够如果你还在...\n",
       "25                                       自已没文化吧。受不了高文化的东西。\n",
       "26                                       自已没文化吧。受不了高文化的东西。\n",
       "27       主要是介绍经络穴位的东西，感觉是东说一点西说一点，内容很零散，且里面的方法说得很模糊，居然会...\n",
       "28       中午收到书了，速度很快，昨天下去才定的，值得表扬~可是收到之后很失望，这本书没有任何包装（可...\n",
       "29                            中国社会科学出版社出的版本可能有删节，但未查到相关说明。\n",
       "                               ...                        \n",
       "10398    买完降价了，店家服务还不错，但安装售后太黑了安装费竟然漫天要价，一开口要378，我不肯买单，...\n",
       "10399    从淘宝客服到送货小哥再到售后检测，态度都很好，都很满意，但是当热水器温度加热到最高温度电源自...\n",
       "10400                            帮别人买的，说很好，就是顺丰慢了点，不过还可以了，\n",
       "10401    良好信誉的商家从小细节做起，抽奖抽到一半球热水壶上面居然写着 真货&rdquo;！！！！还有...\n",
       "10402                   买完后去实体店看了下50升的才680元，没想到比网购还便宜，买贵了。\n",
       "10403    安装费超级贵本来说几十块，安完竟然200块，自己买材料，安装师傅还不给装。卖家倒是服务很好，...\n",
       "10404                                   还好很美观，安装费太贵花了190元。\n",
       "10405      商品包装很好，做工很好！性价比高！但是太原这边Media安装人员收费不便宜，安装用了195元。\n",
       "10406    东西不错，现在这个天早上把水烧到最热断电，晚上回去还可以洗澡。就是这款太老了，没有定时器，不...\n",
       "10407                                 安全阀那略有问题，不过总体不错，好评吧。\n",
       "10408                                   东西不错有的速度很快就是安装师傅黑点\n",
       "10409                               好，物流也快，就是安装费花了200，有点贵。\n",
       "10410                   东西已经装好了，工人师傅挺好的，就是真的好贵，装完要200，太贵了！\n",
       "10411    安装打美的客服电话就可以免费装了，但最好备好材料：3条喉管，1个三通。安装虽然免费，但安装师...\n",
       "10412    东西装修好了，也不知道好不好，可是售后太黑了！买了两个400多的配件费！都无语了！本来在网上...\n",
       "10413             昨天刚装好，试用了一下，不错，家里都有热水了，值得购买的东东。就是安装费好贵啊。\n",
       "10414    加热不是很快，昨天安装上就用了，洗澡洗了半个小时就变成冷水了，不知道是机器的事还是我的事。不...\n",
       "10415                    好评 就是安装用的件有点贵 花了160 建议亲们自己买东西让售后安\n",
       "10416                      很满意 就是安装材料费有点贵花了两百多 棒！ 客服很好 很认真\n",
       "10417    还没装上去，美的货信得过哈哈！不过物流真心麻烦，明明是市区，居然要跑到30公里外收货，对物流...\n",
       "10418    热水器用了一个星期收到！和客服沟通了下，现在就如实评价！！！热水器冷热调节相当不灵敏，太热了...\n",
       "10419    刚开始说好了，有一个四件套，结果给我忘了发，后来补发8天才到。还说什么浴巾就是两根破毛巾。质...\n",
       "10420    客服骗人 不是恒温又说是恒温 噪音大 燃气的味道浓 10号开始使用 17号马上没有热水出 差差差差\n",
       "10421                                 厨宝还好吧  但那赠品送了也跟没送差不多\n",
       "10422    恰逢春节期间，没有安装工人，所以自己动手两块后安装好了，用不了半小时，效果不错，只是送的赠品...\n",
       "10423           安装我自己花了500多，美的够黑心的，真的是烦心，安装的售后叼的要死！差评！！！！！\n",
       "10424                东西不错，售后太差，安装一个热水器400块钱，像话吗？钱给完了发现被黑了！\n",
       "10425    碰到最差的、最骗人的卖家，好吧，我倒霉！这个卖家太不厚道了，显示所在地上海，我买这个热水器选...\n",
       "10426                                      宝贝不错，物流也不错，售后差，\n",
       "10427    美的售后太垃圾，其他售后都是两小时回电话，美的是24小时，结果超过市区不到五公里问我收五十，...\n",
       "Name: 0, Length: 10428, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持一...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持一...\n",
       "1  作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...\n",
       "2  作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...\n",
       "3  作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...\n",
       "4  作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵..."
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "##没有字段名称就用序号0表示\n",
    "#负例标签0，正例标签1\n",
    "for d in neg[0]:\n",
    "    data.append((d, 0))\n",
    "\n",
    "for d in pos[0]:\n",
    "    data.append((d, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data)\n",
    "#data顺序已经被打乱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('不好玩感觉买它是种浪费如果没有认真看它,把它当小说一样看的热情还是不要买了不值得', 0),\n",
       " ('性能非常棒，使命召唤4，5，波斯王子4，极品飞车12效果最高，2倍防锯齿都能流畅运行', 1),\n",
       " ('有些例子不够典型，有滥竽充数之嫌，希望看到的是一些不这么幼稚和明显的中式英语（一般情况下略略学过英语的人都不会犯书中所举的低级错误），应该写一些类似文化差异所造成的“笑话”，如blue story，大多数人只知道blue是忧伤的意思，其实这里变成了黄色小说的意思了。从排版来说，该书还是有可取的地方，看起来比较轻松，有些还是比较好笑的。',\n",
       "  0),\n",
       " ('无express插槽，无e-sata, 屏幕可视角太小，色域也只能算凑合，转轴处塑料感偏重', 0),\n",
       " ('在不敢喝奶，唯恐一不小心被蒙牛，伊利「毒死」的年代，路边阿婆的老酸奶让你放下胃蕾的戒备，难得放心喝一口。', 0),\n",
       " ('房间很冷且不隔音，服务一般，卫生间很小，房间整体舒适性在我住过的如家是最差的。', 0),\n",
       " ('usb接口的位置不怎么好，一个在后面，两个在左边，一般鼠标都在右边，就只有插在后面那个usb接口上，设计有点小问题', 0),\n",
       " ('酒店一般般。 服务态度也不是很好， 主要是人家太忙了。需要等很长时间。要不是要办事里那里很近； 应该不会再住这个了。没有停车的地方。只能停在旁边的有个很大的洗浴的地方。不过那里不错，有兴趣的朋友可以去试试：）',\n",
       "  0),\n",
       " ('介绍说是很好，看了之后，名不副实，说教，空洞。没有实际的事例远远不如另外一本书《遇见未知的自己》好。', 0),\n",
       " (' 酒店位于市中心，比较方便，房间设施较一般，最苦恼的是，说是市政府规定，室外温度不过27度就不能开空调，所以白天几乎不开空调，热得我们没处躲，要知道这可是宾馆不是招待所，房间都是不对流的，不开空调能闷死人呢，真难受啊，还好到晚上空调开了，不然我就立马退房走人了。本市的地图是要买的，不像别的酒店都有赠送。',\n",
       "  0),\n",
       " ('送货快算是个优点吧，我是第一次在京东上买东西，感觉像受骗了一样。京东还号称搞活动返券，结果返了150也不能用，提示说只能消费三千才能用这150；像上了贼船一样。',\n",
       "  1),\n",
       " ('最近受几位老年大学学友的委托，又购买了几本《数码单反摄影轻松入门》和《RAW完全解析》，确实很不错！', 1),\n",
       " ('一个人住第3年，希望越大，失望越大是么？这本书，觉得不知所云，或者，所云无用。觉得浪费钱，适合随手送人。', 0),\n",
       " ('要拿出抵制日货的决心来抵制蒙牛 成年人不喝牛奶 ', 0),\n",
       " ('前天刚刚在国美买了一款A1200，红色的，据说是刚到货的，颜色不错我很满意，4080元买的，带发票，单电单充，含一个128MSD卡（好像没法用）和一个128MTF卡，立体声耳机（听FM的时候非常清晰），两张光盘，数据线。1。用了一天，还不错，只是把声音调到最大的时候我频繁换铃音，死了一次机。2。用习惯了接收短信以后得到发送报告，A1200在发送短信的时候每次都要设置一下，挺麻烦的。3。还有就是日历上没有阴历，对我来说有点不习惯。4。名片识别功能扫起来不大容易，但识别率不错。5。内存太小了，大家都这么讲，我也这么认为。。。6。因为是移动定制手机，有些功能我都不用不到，误按到就要付费，有点可怕。。。7。手写识别率很不错，太出乎我的意料了。。。8。看到卓越上面4888元送蓝牙和打印机（专为这款手机定制的），加50送电池（国产的），听起来很划算，但我打电话问他们客服他们说不知道具体配置，估计没有耳机和数据线，所以我没有冒险买，而且蓝牙对我来说没用，开车的时候用免提就行了，女孩子戴蓝牙太丑了，打印机也很烦，打印出来没地方收藏，还不如放到本本里可以随时看，还不担心纸张和墨墨。。。还有谁用过，大家切磋一下。。。也可发邮件我bjgxtt@sohu.com',\n",
       "  1),\n",
       " ('觉得很多书都比这书好，看到排行榜的排名才买它的，完全没内容，故事太胡扯，不喜欢', 0),\n",
       " ('首先，从外形上看，这款笔记本采用钢琴烤漆，显得格外时尚漂亮；创新的键盘设计颇感人性化，手感也尚佳。 其次，从配置上来看，比较均衡，并且据评测，显卡的能力要比105GM强；LED的屏幕比TFT感觉舒服，200万的摄像头也实用。 最后，这是一款商务本，稳定性强于家用本是不容质疑的；难能可贵的是，散热性极佳，我非常满意！',\n",
       "  1),\n",
       " ('蒙牛就蒙牛吧，总比传说中的三色杯好多了 遗憾哈根达斯变蒙牛 这个吃的真心痛快', 1),\n",
       " ('书质很不错，情节更是吸引人．曾经读过两遍，一直都没有很领略作者的那些妙语，可能跟年龄有关系．及至现在身处围城，再来看这一遍围城，内心里不禁为作者绝妙的语言运用能力拍案叫绝．诙谐，机智，揶揄，深刻的比喻充斥着全文，初始看时，大笑到肚痛，越往后看，渐成苦笑，笑得无奈而心内难受．转而深思．１９４６年的作品，放至今日仍能一一对号入座，周遭不乏此种人，或你或我或他．',\n",
       "  1),\n",
       " ('因为它的名气，我购买了它。也因为它的名气我转送了他人。除了做份礼物送出，对我而言没有任何价值。文中所表述的一切男人女人的特性和家庭问题的解决对我而言都是空的。 没有任何价值来参考，也无法产生任何共鸣。。。。。。。',\n",
       "  0)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 21105)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 按照9:1的比例划分训练集和验证集\n",
    "random_order = range(len(data))\n",
    "random_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# np.random.shuffle(data)\n",
    "\n",
    "#划分训练集和验证集\n",
    "train_data = [data[j] for i, j in enumerate(random_order) if i % 10 != 0]\n",
    "valid_data = [data[j] for i, j in enumerate(random_order) if i % 10 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('性能非常棒，使命召唤4，5，波斯王子4，极品飞车12效果最高，2倍防锯齿都能流畅运行', 1),\n",
       " ('有些例子不够典型，有滥竽充数之嫌，希望看到的是一些不这么幼稚和明显的中式英语（一般情况下略略学过英语的人都不会犯书中所举的低级错误），应该写一些类似文化差异所造成的“笑话”，如blue story，大多数人只知道blue是忧伤的意思，其实这里变成了黄色小说的意思了。从排版来说，该书还是有可取的地方，看起来比较轻松，有些还是比较好笑的。',\n",
       "  0),\n",
       " ('无express插槽，无e-sata, 屏幕可视角太小，色域也只能算凑合，转轴处塑料感偏重', 0),\n",
       " ('在不敢喝奶，唯恐一不小心被蒙牛，伊利「毒死」的年代，路边阿婆的老酸奶让你放下胃蕾的戒备，难得放心喝一口。', 0),\n",
       " ('房间很冷且不隔音，服务一般，卫生间很小，房间整体舒适性在我住过的如家是最差的。', 0),\n",
       " ('usb接口的位置不怎么好，一个在后面，两个在左边，一般鼠标都在右边，就只有插在后面那个usb接口上，设计有点小问题', 0),\n",
       " ('酒店一般般。 服务态度也不是很好， 主要是人家太忙了。需要等很长时间。要不是要办事里那里很近； 应该不会再住这个了。没有停车的地方。只能停在旁边的有个很大的洗浴的地方。不过那里不错，有兴趣的朋友可以去试试：）',\n",
       "  0),\n",
       " ('介绍说是很好，看了之后，名不副实，说教，空洞。没有实际的事例远远不如另外一本书《遇见未知的自己》好。', 0),\n",
       " (' 酒店位于市中心，比较方便，房间设施较一般，最苦恼的是，说是市政府规定，室外温度不过27度就不能开空调，所以白天几乎不开空调，热得我们没处躲，要知道这可是宾馆不是招待所，房间都是不对流的，不开空调能闷死人呢，真难受啊，还好到晚上空调开了，不然我就立马退房走人了。本市的地图是要买的，不像别的酒店都有赠送。',\n",
       "  0),\n",
       " ('最近受几位老年大学学友的委托，又购买了几本《数码单反摄影轻松入门》和《RAW完全解析》，确实很不错！', 1)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##进行padding补零处理;这里似乎padding之后没有经过mask处理在计算loss的时候；\n",
    "##原始bert中pad对应0，直接使用预训练模型，pad也要对应0\n",
    "def seq_padding(X, padding=0):\n",
    "    L = [len(x) for x in X]\n",
    "    ML = max(L)\n",
    "    return np.array([\n",
    "        np.concatenate([x, [padding] * (ML - len(x))]) if len(x) < ML else x for x in X\n",
    "    ])\n",
    "\n",
    "\n",
    "class data_generator:\n",
    "    def __init__(self, data, batch_size=32):\n",
    "        self.data = data\n",
    "        '''\n",
    "        data数据形式如下：\n",
    "        [('性能非常棒，使命召唤4，5，波斯王子4，极品飞车12效果最高，2倍防锯齿都能流畅运行', 1),\n",
    "         ('有些例子不够典型，有滥竽充数之嫌，希望看到的是一些不这么幼稚和明显的中式英语（一般情况下略略学过英语的人都不会犯书中所举的低级错误），应该写一些类似文化差异所造成的“笑话”，如blue story，大多数人只知道blue是忧伤的意思，其实这里变成了黄色小说的意思了。从排版来说，该书还是有可取的地方，看起来比较轻松，有些还是比较好笑的。',\n",
    "  0),\n",
    "        '''\n",
    "        self.batch_size = batch_size\n",
    "        self.steps = len(self.data) // self.batch_size\n",
    "        #取整后如果不够在多加一步\n",
    "        if len(self.data) % self.batch_size != 0:\n",
    "            self.steps += 1\n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            idxs = range(len(self.data))#range(0, 21105)\n",
    "            np.random.shuffle(self.data)#将data顺序打乱\n",
    "            X1, X2, Y = [], [], []\n",
    "            #根据序号取出每一个数据\n",
    "            for i in idxs:\n",
    "                d = self.data[i]\n",
    "                text = d[0][:maxlen]#序号0对应文本内容，且截取最长字符个数；1对应类别标签\n",
    "                #数据编码；得到句中每个字的id,以及该句话的id(0第一句，1第二句)\n",
    "                x1, x2 = tokenizer.encode(first=text)\n",
    "                '''\n",
    "                x1=indices=[101, 691, 6205, 679, 7231, 8024, 1545, 1400, 1922, 2345, 8024, 2128, 6163, 671, 702, 4178, 3717, 1690, 125, 121, 121, 1779, 7178, 8024, 1008, 6413, 1408, 8043, 7178, 5314, 2130, 749, 1355, 4385, 6158, 7946, 749, 8013, 102] \n",
    "                x2=segments=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "                '''\n",
    "                \n",
    "                y = d[1]#1对应类别标签\n",
    "                X1.append(x1)#将每句话中所有字的indices组成的列表放到一个新列表里\n",
    "                X2.append(x2)#将每句话中所有字的segments组成的列表放到一个新列表里\n",
    "                Y.append([y])#每个标签组成的列表放到新列表里\n",
    "                #满足一个batch或者结束了就返回\n",
    "                if len(X1) == self.batch_size or i == idxs[-1]:\n",
    "                    X1 = seq_padding(X1)\n",
    "                    X2 = seq_padding(X2)\n",
    "                    Y = seq_padding(Y)\n",
    "                    ##返回格式如下，X1，X2，Y都是二维列表\n",
    "                    yield [X1, X2], Y\n",
    "                    #每一个批次返回后就置空\n",
    "                    [X1, X2, Y] = [], [], []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_D = data_generator(train_data)\n",
    "valid_D = data_generator(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "g=train_D.__iter__()#batch_size=32,返回一个batch的数据\n",
    "d=next(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[ 101,  671, 4684, ..., 5491, 5489,  102],\n",
       "         [ 101, 6821, 3315, ..., 2190, 3124,  102],\n",
       "         [ 101, 3341, 5722, ..., 2697, 6230,  102],\n",
       "         ...,\n",
       "         [ 101,  671,  702, ...,    0,    0,    0],\n",
       "         [ 101,  779, 4263, ..., 6632, 3341,  102],\n",
       "         [ 101, 5709,  749, ..., 1431, 8024,  102]]),\n",
       "  array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]])],\n",
       " array([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1]]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 102])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 102])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 1])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x1_in, x2_in]=d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=90799, shape=(32, 102), dtype=int64, numpy=\n",
       " array([[ 101,    1, 5885, ...,    0,    0,    0],\n",
       "        [ 101,  147,  124, ...,    0,    0,    0],\n",
       "        [ 101,  100,  100, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 4696, 3221, ..., 1990, 2823,  102],\n",
       "        [ 101, 6968, 6228, ...,    0,    0,    0],\n",
       "        [ 101,  966, 2533, ...,  741, 7027,  102]])>,\n",
       " <tf.Tensor: id=90800, shape=(32, 102), dtype=int64, numpy=\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 32, 102)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x1_in).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 1])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer model_15 was called with an input that isn't a symbolic tensor. Received type: <class 'list'>. Full input: [[<tf.Tensor: id=90799, shape=(32, 102), dtype=int64, numpy=\narray([[ 101,    1, 5885, ...,    0,    0,    0],\n       [ 101,  147,  124, ...,    0,    0,    0],\n       [ 101,  100,  100, ...,    0,    0,    0],\n       ...,\n       [ 101, 4696, 3221, ..., 1990, 2823,  102],\n       [ 101, 6968, 6228, ...,    0,    0,    0],\n       [ 101,  966, 2533, ...,  741, 7027,  102]])>, <tf.Tensor: id=90800, shape=(32, 102), dtype=int64, numpy=\narray([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]])>], <tf.Tensor: id=90801, shape=(32, 1), dtype=int64, numpy=\narray([[0],\n       [0],\n       [1],\n       [0],\n       [0],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1],\n       [0],\n       [0],\n       [1],\n       [0],\n       [1],\n       [1],\n       [0],\n       [0],\n       [0],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1]])>]. All inputs to the layer should be tensors.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                 \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    696\u001b[0m         raise ValueError('Unexpectedly found an instance of type `' +\n\u001b[0;32m--> 697\u001b[0;31m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m                          'Expected a symbolic tensor instance.')\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'list'>`. Expected a symbolic tensor instance.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-474d55af6ef0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx1_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# with the input_spec set at build time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;31m# Handle mask propagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                                  \u001b[0;34m'Received type: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full input: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. All inputs to the layer '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                                  'should be tensors.')\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer model_15 was called with an input that isn't a symbolic tensor. Received type: <class 'list'>. Full input: [[<tf.Tensor: id=90799, shape=(32, 102), dtype=int64, numpy=\narray([[ 101,    1, 5885, ...,    0,    0,    0],\n       [ 101,  147,  124, ...,    0,    0,    0],\n       [ 101,  100,  100, ...,    0,    0,    0],\n       ...,\n       [ 101, 4696, 3221, ..., 1990, 2823,  102],\n       [ 101, 6968, 6228, ...,    0,    0,    0],\n       [ 101,  966, 2533, ...,  741, 7027,  102]])>, <tf.Tensor: id=90800, shape=(32, 102), dtype=int64, numpy=\narray([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]])>], <tf.Tensor: id=90801, shape=(32, 1), dtype=int64, numpy=\narray([[0],\n       [0],\n       [1],\n       [0],\n       [0],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1],\n       [0],\n       [0],\n       [1],\n       [0],\n       [1],\n       [1],\n       [0],\n       [0],\n       [0],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1]])>]. All inputs to the layer should be tensors."
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "bert_model = load_trained_model_from_checkpoint(config_path, checkpoint_path, seq_len=None)\n",
    "\n",
    "for l in bert_model.layers:\n",
    "    l.trainable = True\n",
    "\n",
    "# x1_in = Input(shape=(None,))\n",
    "# x2_in = Input(shape=(None,))\n",
    "\n",
    "#[x1_in, x2_in]=([X1=indices, X2=segments], Y)\n",
    "#x1_in=[X1,X2]\n",
    "#x2_in=Y\n",
    "\n",
    "\n",
    "\n",
    "x = bert_model([x1_in, x2_in])\n",
    "\n",
    "print(x.shape)\n",
    "##shape=(None, None, 768)=（batch_size,seq_length,hidden_size）\n",
    "##QA那个就可以接在这个后面，预训练情况下，用bert的encoder端结构足够了，本身就很复杂\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.training.Model"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Model in module keras.engine.training object:\n",
      "\n",
      "class Model(keras.engine.network.Network)\n",
      " |  The `Model` class adds training & evaluation routines to a `Network`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Model\n",
      " |      keras.engine.network.Network\n",
      " |      keras.engine.base_layer.Layer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  compile(self, optimizer, loss=None, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None, **kwargs)\n",
      " |      Configures the model for training.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          optimizer: String (name of optimizer) or optimizer instance.\n",
      " |              See [optimizers](/optimizers).\n",
      " |          loss: String (name of objective function) or objective function or\n",
      " |              `Loss` instance. See [losses](/losses).\n",
      " |              If the model has multiple outputs, you can use a different loss\n",
      " |              on each output by passing a dictionary or a list of losses.\n",
      " |              The loss value that will be minimized by the model\n",
      " |              will then be the sum of all individual losses.\n",
      " |          metrics: List of metrics to be evaluated by the model\n",
      " |              during training and testing. Typically you will use\n",
      " |              `metrics=['accuracy']`. To specify different metrics for different\n",
      " |              outputs of a multi-output model, you could also pass a dictionary,\n",
      " |              such as\n",
      " |              `metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.\n",
      " |              You can also pass a list (len = len(outputs)) of lists of metrics\n",
      " |              such as `metrics=[['accuracy'], ['accuracy', 'mse']]` or\n",
      " |              `metrics=['accuracy', ['accuracy', 'mse']]`.\n",
      " |          loss_weights: Optional list or dictionary specifying scalar\n",
      " |              coefficients (Python floats) to weight the loss contributions\n",
      " |              of different model outputs.\n",
      " |              The loss value that will be minimized by the model\n",
      " |              will then be the *weighted sum* of all individual losses,\n",
      " |              weighted by the `loss_weights` coefficients.\n",
      " |              If a list, it is expected to have a 1:1 mapping\n",
      " |              to the model's outputs. If a dict, it is expected to map\n",
      " |              output names (strings) to scalar coefficients.\n",
      " |          sample_weight_mode: If you need to do timestep-wise\n",
      " |              sample weighting (2D weights), set this to `\"temporal\"`.\n",
      " |              `None` defaults to sample-wise weights (1D).\n",
      " |              If the model has multiple outputs, you can use a different\n",
      " |              `sample_weight_mode` on each output by passing a\n",
      " |              dictionary or a list of modes.\n",
      " |          weighted_metrics: List of metrics to be evaluated and weighted\n",
      " |              by sample_weight or class_weight during training and testing.\n",
      " |          target_tensors: By default, Keras will create placeholders for the\n",
      " |              model's target, which will be fed with the target data during\n",
      " |              training. If instead you would like to use your own\n",
      " |              target tensors (in turn, Keras will not expect external\n",
      " |              Numpy data for these targets at training time), you\n",
      " |              can specify them via the `target_tensors` argument. It can be\n",
      " |              a single tensor (for a single-output model), a list of tensors,\n",
      " |              or a dict mapping output names to target tensors.\n",
      " |          **kwargs: When using the Theano/CNTK backends, these arguments\n",
      " |              are passed into `K.function`.\n",
      " |              When using the TensorFlow backend,\n",
      " |              these arguments are passed into `tf.Session.run`.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of invalid arguments for\n",
      " |              `optimizer`, `loss`, `metrics` or `sample_weight_mode`.\n",
      " |  \n",
      " |  evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Returns the loss value & metrics values for the model in test mode.\n",
      " |      \n",
      " |      Computation is done in batches.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Input data. It could be:\n",
      " |              - A Numpy array (or array-like), or a list of arrays\n",
      " |                (in case the model has multiple inputs).\n",
      " |              - A dict mapping input names to the corresponding\n",
      " |                array/tensors, if the model has named inputs.\n",
      " |              - A generator or `keras.utils.Sequence` returning\n",
      " |                `(inputs, targets)` or `(inputs, targets, sample weights)`.\n",
      " |              - None (default) if feeding from framework-native\n",
      " |                tensors (e.g. TensorFlow data tensors).\n",
      " |          y: Target data. Like the input data `x`,\n",
      " |              it could be either Numpy array(s), framework-native tensor(s),\n",
      " |              list of Numpy arrays (if the model has multiple outputs) or\n",
      " |              None (default) if feeding from framework-native tensors\n",
      " |              (e.g. TensorFlow data tensors).\n",
      " |              If output layers in the model are named, you can also pass a\n",
      " |              dictionary mapping output names to Numpy arrays.\n",
      " |              If `x` is a generator, or `keras.utils.Sequence` instance,\n",
      " |              `y` should not be specified (since targets will be obtained\n",
      " |              from `x`).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of symbolic tensors, generators, or\n",
      " |              `keras.utils.Sequence` instances (since they generate batches).\n",
      " |          verbose: 0 or 1. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the test samples, used for weighting the loss function.\n",
      " |              You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              `sample_weight_mode=\"temporal\"` in `compile()`.\n",
      " |          steps: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring the evaluation round finished.\n",
      " |              Ignored with the default value of `None`.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during evaluation.\n",
      " |              See [callbacks](/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up when using\n",
      " |              process-based threading. If unspecified, `workers` will default\n",
      " |              to 1. If 0, will execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case of invalid arguments.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |  \n",
      " |  evaluate_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Evaluates the model on a data generator.\n",
      " |      \n",
      " |      The generator should return the same kind of data\n",
      " |      as accepted by `test_on_batch`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          generator: Generator yielding tuples (inputs, targets)\n",
      " |              or (inputs, targets, sample_weights)\n",
      " |              or an instance of Sequence (keras.utils.Sequence)\n",
      " |              object in order to avoid duplicate data\n",
      " |              when using multiprocessing.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              to yield from `generator` before stopping.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(generator)` as a number of steps.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See [callbacks](/callbacks).\n",
      " |          max_queue_size: maximum size for the generator queue\n",
      " |          workers: Integer. Maximum number of processes to spin up\n",
      " |              when using process based threading.\n",
      " |              If unspecified, `workers` will default to 1. If 0, will\n",
      " |              execute the generator on the main thread.\n",
      " |          use_multiprocessing: if True, use process based threading.\n",
      " |              Note that because\n",
      " |              this implementation relies on multiprocessing,\n",
      " |              you should not pass\n",
      " |              non picklable arguments to the generator\n",
      " |              as they can't be passed\n",
      " |              easily to children processes.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case the generator yields\n",
      " |              data in an invalid format.\n",
      " |  \n",
      " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False, **kwargs)\n",
      " |      Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Input data. It could be:\n",
      " |              - A Numpy array (or array-like), or a list of arrays\n",
      " |                (in case the model has multiple inputs).\n",
      " |              - A dict mapping input names to the corresponding\n",
      " |                array/tensors, if the model has named inputs.\n",
      " |              - A generator or `keras.utils.Sequence` returning\n",
      " |                `(inputs, targets)` or `(inputs, targets, sample weights)`.\n",
      " |              - None (default) if feeding from framework-native\n",
      " |                tensors (e.g. TensorFlow data tensors).\n",
      " |          y: Target data. Like the input data `x`,\n",
      " |              it could be either Numpy array(s), framework-native tensor(s),\n",
      " |              list of Numpy arrays (if the model has multiple outputs) or\n",
      " |              None (default) if feeding from framework-native tensors\n",
      " |              (e.g. TensorFlow data tensors).\n",
      " |              If output layers in the model are named, you can also pass a\n",
      " |              dictionary mapping output names to Numpy arrays.\n",
      " |              If `x` is a generator, or `keras.utils.Sequence` instance,\n",
      " |              `y` should not be specified (since targets will be obtained\n",
      " |              from `x`).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of symbolic tensors, generators, or `Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          epochs: Integer. Number of epochs to train the model.\n",
      " |              An epoch is an iteration over the entire `x` and `y`\n",
      " |              data provided.\n",
      " |              Note that in conjunction with `initial_epoch`,\n",
      " |              `epochs` is to be understood as \"final epoch\".\n",
      " |              The model is not trained for a number of iterations\n",
      " |              given by `epochs`, but merely until the epoch\n",
      " |              of index `epochs` is reached.\n",
      " |          verbose: Integer. 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training and validation\n",
      " |              (if ).\n",
      " |              See [callbacks](/callbacks).\n",
      " |          validation_split: Float between 0 and 1.\n",
      " |              Fraction of the training data to be used as validation data.\n",
      " |              The model will set apart this fraction of the training data,\n",
      " |              will not train on it, and will evaluate\n",
      " |              the loss and any model metrics\n",
      " |              on this data at the end of each epoch.\n",
      " |              The validation data is selected from the last samples\n",
      " |              in the `x` and `y` data provided, before shuffling.\n",
      " |              This argument is not supported when `x` is a generator or\n",
      " |              `Sequence` instance.\n",
      " |          validation_data: Data on which to evaluate\n",
      " |              the loss and any model metrics at the end of each epoch.\n",
      " |              The model will not be trained on this data.\n",
      " |              `validation_data` will override `validation_split`.\n",
      " |              `validation_data` could be:\n",
      " |                  - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
      " |                  - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
      " |                  - dataset or a dataset iterator\n",
      " |              For the first two cases, `batch_size` must be provided.\n",
      " |              For the last case, `validation_steps` must be provided.\n",
      " |          shuffle: Boolean (whether to shuffle the training data\n",
      " |              before each epoch) or str (for 'batch').\n",
      " |              'batch' is a special option for dealing with the\n",
      " |              limitations of HDF5 data; it shuffles in batch-sized chunks.\n",
      " |              Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only).\n",
      " |              This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples from\n",
      " |              an under-represented class.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the training samples, used for weighting the loss function\n",
      " |              (during training only). You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              `sample_weight_mode=\"temporal\"` in `compile()`. This argument\n",
      " |              is not supported when `x` generator, or `Sequence` instance,\n",
      " |              instead provide the sample_weights as the third element of `x`.\n",
      " |          initial_epoch: Integer.\n",
      " |              Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |          steps_per_epoch: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring one epoch finished and starting the\n",
      " |              next epoch. When training with input tensors such as\n",
      " |              TensorFlow data tensors, the default `None` is equal to\n",
      " |              the number of samples in your dataset divided by\n",
      " |              the batch size, or 1 if that cannot be determined.\n",
      " |          validation_steps: Only relevant if `steps_per_epoch`\n",
      " |              is specified. Total number of steps (batches of samples)\n",
      " |              to validate before stopping.\n",
      " |          validation_steps: Only relevant if `validation_data` is provided\n",
      " |              and is a generator. Total number of steps (batches of samples)\n",
      " |              to draw before stopping when performing validation at the end\n",
      " |              of every epoch.\n",
      " |          validation_freq: Only relevant if validation data is provided. Integer\n",
      " |              or list/tuple/set. If an integer, specifies how many training\n",
      " |              epochs to run before a new validation run is performed, e.g.\n",
      " |              `validation_freq=2` runs validation every 2 epochs. If a list,\n",
      " |              tuple, or set, specifies the epochs on which to run validation,\n",
      " |              e.g. `validation_freq=[1, 2, 10]` runs validation at the end\n",
      " |              of the 1st, 2nd, and 10th epochs.\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up\n",
      " |              when using process-based threading. If unspecified, `workers`\n",
      " |              will default to 1. If 0, will execute the generator on the main\n",
      " |              thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |          **kwargs: Used for backwards compatibility.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A `History` object. Its `History.history` attribute is\n",
      " |          a record of training loss values and metrics values\n",
      " |          at successive epochs, as well as validation loss values\n",
      " |          and validation metrics values (if applicable).\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: If the model was never compiled.\n",
      " |          ValueError: In case of mismatch between the provided input data\n",
      " |              and what the model expects.\n",
      " |  \n",
      " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
      " |      Trains the model on data generated batch-by-batch by a Python generator\n",
      " |      (or an instance of `Sequence`).\n",
      " |      \n",
      " |      The generator is run in parallel to the model, for efficiency.\n",
      " |      For instance, this allows you to do real-time data augmentation\n",
      " |      on images on CPU in parallel to training your model on GPU.\n",
      " |      \n",
      " |      The use of `keras.utils.Sequence` guarantees the ordering\n",
      " |      and guarantees the single use of every input per epoch when\n",
      " |      using `use_multiprocessing=True`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          generator: A generator or an instance of `Sequence`\n",
      " |              (`keras.utils.Sequence`) object in order to avoid\n",
      " |              duplicate data when using multiprocessing.\n",
      " |              The output of the generator must be either\n",
      " |              - a tuple `(inputs, targets)`\n",
      " |              - a tuple `(inputs, targets, sample_weights)`.\n",
      " |              This tuple (a single output of the generator) makes a single\n",
      " |              batch. Therefore, all arrays in this tuple must have the same\n",
      " |              length (equal to the size of this batch). Different batches may\n",
      " |              have different sizes. For example, the last batch of the epoch\n",
      " |              is commonly smaller than the others, if the size of the dataset\n",
      " |              is not divisible by the batch size.\n",
      " |              The generator is expected to loop over its data\n",
      " |              indefinitely. An epoch finishes when `steps_per_epoch`\n",
      " |              batches have been seen by the model.\n",
      " |          steps_per_epoch: Integer.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              to yield from `generator` before declaring one epoch\n",
      " |              finished and starting the next epoch. It should typically\n",
      " |              be equal to `ceil(num_samples / batch_size)`\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(generator)` as a number of steps.\n",
      " |          epochs: Integer. Number of epochs to train the model.\n",
      " |              An epoch is an iteration over the entire data provided,\n",
      " |              as defined by `steps_per_epoch`.\n",
      " |              Note that in conjunction with `initial_epoch`,\n",
      " |              `epochs` is to be understood as \"final epoch\".\n",
      " |              The model is not trained for a number of iterations\n",
      " |              given by `epochs`, but merely until the epoch\n",
      " |              of index `epochs` is reached.\n",
      " |          verbose: Integer. 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See [callbacks](/callbacks).\n",
      " |          validation_data: This can be either\n",
      " |              - a generator or a `Sequence` object for the validation data\n",
      " |              - tuple `(x_val, y_val)`\n",
      " |              - tuple `(x_val, y_val, val_sample_weights)`\n",
      " |              on which to evaluate\n",
      " |              the loss and any model metrics at the end of each epoch.\n",
      " |              The model will not be trained on this data.\n",
      " |          validation_steps: Only relevant if `validation_data`\n",
      " |              is a generator. Total number of steps (batches of samples)\n",
      " |              to yield from `validation_data` generator before stopping\n",
      " |              at the end of every epoch. It should typically\n",
      " |              be equal to the number of samples of your\n",
      " |              validation dataset divided by the batch size.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(validation_data)` as a number of steps.\n",
      " |          validation_freq: Only relevant if validation data is provided. Integer\n",
      " |              or `collections.Container` instance (e.g. list, tuple, etc.). If an\n",
      " |              integer, specifies how many training epochs to run before a new\n",
      " |              validation run is performed, e.g. `validation_freq=2` runs\n",
      " |              validation every 2 epochs. If a Container, specifies the epochs on\n",
      " |              which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
      " |              validation at the end of the 1st, 2nd, and 10th epochs.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only). This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples\n",
      " |              from an under-represented class.\n",
      " |          max_queue_size: Integer. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Maximum number of processes to spin up\n",
      " |              when using process-based threading.\n",
      " |              If unspecified, `workers` will default to 1. If 0, will\n",
      " |              execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean.\n",
      " |              If `True`, use process-based threading.\n",
      " |              If unspecified, `use_multiprocessing` will default to `False`.\n",
      " |              Note that because this implementation\n",
      " |              relies on multiprocessing,\n",
      " |              you should not pass non-picklable arguments to the generator\n",
      " |              as they can't be passed easily to children processes.\n",
      " |          shuffle: Boolean. Whether to shuffle the order of the batches at\n",
      " |              the beginning of each epoch. Only used with instances\n",
      " |              of `Sequence` (`keras.utils.Sequence`).\n",
      " |              Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          initial_epoch: Integer.\n",
      " |              Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A `History` object. Its `History.history` attribute is\n",
      " |          a record of training loss values and metrics values\n",
      " |          at successive epochs, as well as validation loss values\n",
      " |          and validation metrics values (if applicable).\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case the generator yields data in an invalid format.\n",
      " |      \n",
      " |      # Example\n",
      " |      \n",
      " |      ```python\n",
      " |      def generate_arrays_from_file(path):\n",
      " |          while True:\n",
      " |              with open(path) as f:\n",
      " |                  for line in f:\n",
      " |                      # create numpy arrays of input data\n",
      " |                      # and labels, from each line in the file\n",
      " |                      x1, x2, y = process_line(line)\n",
      " |                      yield ({'input_1': x1, 'input_2': x2}, {'output': y})\n",
      " |      \n",
      " |      model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n",
      " |                          steps_per_epoch=10000, epochs=10)\n",
      " |      ```\n",
      " |  \n",
      " |  predict(self, x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Generates output predictions for the input samples.\n",
      " |      \n",
      " |      Computation is done in batches.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Input data. It could be:\n",
      " |              - A Numpy array (or array-like), or a list of arrays\n",
      " |                (in case the model has multiple inputs).\n",
      " |              - A dict mapping input names to the corresponding\n",
      " |                array/tensors, if the model has named inputs.\n",
      " |              - A generator or `keras.utils.Sequence` returning\n",
      " |                `(inputs, targets)` or `(inputs, targets, sample weights)`.\n",
      " |              - None (default) if feeding from framework-native\n",
      " |                tensors (e.g. TensorFlow data tensors).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of symbolic tensors, generators, or\n",
      " |              `keras.utils.Sequence` instances (since they generate batches).\n",
      " |          verbose: Verbosity mode, 0 or 1.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              before declaring the prediction round finished.\n",
      " |              Ignored with the default value of `None`.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during prediction.\n",
      " |              See [callbacks](/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up when using\n",
      " |              process-based threading. If unspecified, `workers` will default\n",
      " |              to 1. If 0, will execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of mismatch between the provided\n",
      " |              input data and the model's expectations,\n",
      " |              or in case a stateful model receives a number of samples\n",
      " |              that is not a multiple of the batch size.\n",
      " |  \n",
      " |  predict_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Generates predictions for the input samples from a data generator.\n",
      " |      \n",
      " |      The generator should return the same kind of data as accepted by\n",
      " |      `predict_on_batch`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          generator: Generator yielding batches of input samples\n",
      " |              or an instance of Sequence (keras.utils.Sequence)\n",
      " |              object in order to avoid duplicate data\n",
      " |              when using multiprocessing.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              to yield from `generator` before stopping.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(generator)` as a number of steps.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See [callbacks](/callbacks).\n",
      " |          max_queue_size: Maximum size for the generator queue.\n",
      " |          workers: Integer. Maximum number of processes to spin up\n",
      " |              when using process based threading.\n",
      " |              If unspecified, `workers` will default to 1. If 0, will\n",
      " |              execute the generator on the main thread.\n",
      " |          use_multiprocessing: If `True`, use process based threading.\n",
      " |              Note that because\n",
      " |              this implementation relies on multiprocessing,\n",
      " |              you should not pass\n",
      " |              non picklable arguments to the generator\n",
      " |              as they can't be passed\n",
      " |              easily to children processes.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case the generator yields\n",
      " |              data in an invalid format.\n",
      " |  \n",
      " |  predict_on_batch(self, x)\n",
      " |      Returns predictions for a single batch of samples.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Input samples, as a Numpy array.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Numpy array(s) of predictions.\n",
      " |  \n",
      " |  reset_metrics(self)\n",
      " |      Resets the state of metrics.\n",
      " |  \n",
      " |  test_on_batch(self, x, y, sample_weight=None, reset_metrics=True)\n",
      " |      Test the model on a single batch of samples.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Numpy array of test data,\n",
      " |              or list of Numpy arrays if the model has multiple inputs.\n",
      " |              If all inputs in the model are named,\n",
      " |              you can also pass a dictionary\n",
      " |              mapping input names to Numpy arrays.\n",
      " |          y: Numpy array of target data,\n",
      " |              or list of Numpy arrays if the model has multiple outputs.\n",
      " |              If all outputs in the model are named,\n",
      " |              you can also pass a dictionary\n",
      " |              mapping output names to Numpy arrays.\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |              weights to apply to the model's loss for each sample.\n",
      " |              In the case of temporal data, you can pass a 2D array\n",
      " |              with shape (samples, sequence_length),\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              sample_weight_mode=\"temporal\" in compile().\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |              batch. If `False`, the metrics will be statefully accumulated across\n",
      " |              batches.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |  \n",
      " |  train_on_batch(self, x, y, sample_weight=None, class_weight=None, reset_metrics=True)\n",
      " |      Runs a single gradient update on a single batch of data.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Numpy array of training data,\n",
      " |              or list of Numpy arrays if the model has multiple inputs.\n",
      " |              If all inputs in the model are named,\n",
      " |              you can also pass a dictionary\n",
      " |              mapping input names to Numpy arrays.\n",
      " |          y: Numpy array of target data,\n",
      " |              or list of Numpy arrays if the model has multiple outputs.\n",
      " |              If all outputs in the model are named,\n",
      " |              you can also pass a dictionary\n",
      " |              mapping output names to Numpy arrays.\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |              weights to apply to the model's loss for each sample.\n",
      " |              In the case of temporal data, you can pass a 2D array\n",
      " |              with shape (samples, sequence_length),\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              sample_weight_mode=\"temporal\" in compile().\n",
      " |          class_weight: Optional dictionary mapping\n",
      " |              class indices (integers) to\n",
      " |              a weight (float) to apply to the model's loss for the samples\n",
      " |              from this class during training.\n",
      " |              This can be useful to tell the model to \"pay more attention\" to\n",
      " |              samples from an under-represented class.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |              batch. If `False`, the metrics will be statefully accumulated across\n",
      " |              batches.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Scalar training loss\n",
      " |          (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  metrics\n",
      " |      Returns the model's metrics added using `compile`, `add_metric` APIs.\n",
      " |  \n",
      " |  metrics_names\n",
      " |      Returns the model's display labels for all outputs.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.network.Network:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __init__(self, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  call(self, inputs, mask=None)\n",
      " |      Calls the model on new inputs.\n",
      " |      \n",
      " |      In this case `call` just reapplies\n",
      " |      all ops in the graph to the new inputs\n",
      " |      (e.g. build a new computational graph from the provided inputs).\n",
      " |      \n",
      " |      A model is callable on non-Keras tensors.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: A tensor or list of tensors.\n",
      " |          mask: A mask or list of masks. A mask can be\n",
      " |              either a tensor or None (no mask).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor if there is a single output, or\n",
      " |          a list of tensors if there are more than one outputs.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      # Returns\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      Assumes that the layer will be built\n",
      " |      to match that input shape provided.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An output shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  get_layer(self, name=None, index=None)\n",
      " |      Retrieves a layer based on either its name (unique) or index.\n",
      " |      \n",
      " |      If `name` and `index` are both provided, `index` will take precedence.\n",
      " |      \n",
      " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, name of layer.\n",
      " |          index: Integer, index of layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A layer instance.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of invalid layer name or index.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Retrieves the weights of the model.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A flat list of Numpy arrays.\n",
      " |  \n",
      " |  load_weights(self, filepath, by_name=False, skip_mismatch=False, reshape=False)\n",
      " |      Loads all layer weights from a HDF5 save file.\n",
      " |      \n",
      " |      If `by_name` is False (default) weights are loaded\n",
      " |      based on the network's topology, meaning the architecture\n",
      " |      should be the same as when the weights were saved.\n",
      " |      Note that layers that don't have weights are not taken\n",
      " |      into account in the topological ordering, so adding or\n",
      " |      removing layers is fine as long as they don't have weights.\n",
      " |      \n",
      " |      If `by_name` is True, weights are loaded into layers\n",
      " |      only if they share the same name. This is useful\n",
      " |      for fine-tuning or transfer-learning models where\n",
      " |      some of the layers have changed.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          filepath: String, path to the weights file to load.\n",
      " |          by_name: Boolean, whether to load weights by name\n",
      " |              or by topological order.\n",
      " |          skip_mismatch: Boolean, whether to skip loading of layers\n",
      " |              where there is a mismatch in the number of weights,\n",
      " |              or a mismatch in the shape of the weight\n",
      " |              (only valid when `by_name`=True).\n",
      " |          reshape: Reshape weights to fit the layer when the correct number\n",
      " |              of weight arrays is present but their shape does not match.\n",
      " |      \n",
      " |      \n",
      " |      # Raises\n",
      " |          ImportError: If h5py is not available.\n",
      " |  \n",
      " |  reset_states(self)\n",
      " |  \n",
      " |  run_internal_graph(self, inputs, masks=None)\n",
      " |      Computes output tensors for new inputs.\n",
      " |      \n",
      " |      # Note:\n",
      " |          - Expects `inputs` to be a list (potentially with 1 element).\n",
      " |          - Can be run on non-Keras tensors.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: List of tensors\n",
      " |          masks: List of masks (tensors or None).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Three lists: output_tensors, output_masks, output_shapes\n",
      " |  \n",
      " |  save(self, filepath, overwrite=True, include_optimizer=True)\n",
      " |      Saves the model to a single HDF5 file.\n",
      " |      \n",
      " |      The savefile includes:\n",
      " |          - The model architecture, allowing to re-instantiate the model.\n",
      " |          - The model weights.\n",
      " |          - The state of the optimizer, allowing to resume training\n",
      " |              exactly where you left off.\n",
      " |      \n",
      " |      This allows you to save the entirety of the state of a model\n",
      " |      in a single file.\n",
      " |      \n",
      " |      Saved models can be reinstantiated via `keras.models.load_model`.\n",
      " |      The model returned by `load_model`\n",
      " |      is a compiled model ready to be used (unless the saved model\n",
      " |      was never compiled in the first place).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          filepath: one of the following:\n",
      " |              - string, path to the file to save the model to\n",
      " |              - h5py.File or h5py.Group object where to save the model\n",
      " |              - any file-like object implementing the method `write` that accepts\n",
      " |                  `bytes` data (e.g. `io.BytesIO`).\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          include_optimizer: If True, save optimizer's state together.\n",
      " |      \n",
      " |      # Example\n",
      " |      \n",
      " |      ```python\n",
      " |      from keras.models import load_model\n",
      " |      \n",
      " |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
      " |      del model  # deletes the existing model\n",
      " |      \n",
      " |      # returns a compiled model\n",
      " |      # identical to the previous one\n",
      " |      model = load_model('my_model.h5')\n",
      " |      ```\n",
      " |  \n",
      " |  save_weights(self, filepath, overwrite=True)\n",
      " |      Dumps all layer weights to a HDF5 file.\n",
      " |      \n",
      " |      The weight file has:\n",
      " |          - `layer_names` (attribute), a list of strings\n",
      " |              (ordered names of model layers).\n",
      " |          - For every layer, a `group` named `layer.name`\n",
      " |              - For every such layer group, a group attribute `weight_names`,\n",
      " |                  a list of strings\n",
      " |                  (ordered names of weights tensor of the layer).\n",
      " |              - For every weight in the layer, a dataset\n",
      " |                  storing the weight value, named after the weight tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          filepath: String, path to the file to save the weights to.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ImportError: If h5py is not available.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the model.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          weights: A list of Numpy arrays with shapes and types matching\n",
      " |              the output of `model.get_weights()`.\n",
      " |  \n",
      " |  summary(self, line_length=None, positions=None, print_fn=None)\n",
      " |      Prints a string summary of the network.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          line_length: Total length of printed lines\n",
      " |              (e.g. set this to adapt the display to different\n",
      " |              terminal window sizes).\n",
      " |          positions: Relative or absolute positions of log elements\n",
      " |              in each line. If not provided,\n",
      " |              defaults to `[.33, .55, .67, 1.]`.\n",
      " |          print_fn: Print function to use.\n",
      " |              It will be called on each line of the summary.\n",
      " |              You can set it to a custom function\n",
      " |              in order to capture the string summary.\n",
      " |              It defaults to `print` (prints to stdout).\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a JSON save file, use\n",
      " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `json.dumps()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A JSON string.\n",
      " |  \n",
      " |  to_yaml(self, **kwargs)\n",
      " |      Returns a yaml string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a yaml save file, use\n",
      " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
      " |      \n",
      " |      `custom_objects` should be a dictionary mapping\n",
      " |      the names of custom losses / layers / etc to the corresponding\n",
      " |      functions / classes.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `yaml.dump()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A YAML string.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.network.Network:\n",
      " |  \n",
      " |  from_config(config, custom_objects=None) from builtins.type\n",
      " |      Instantiates a Model from its config (output of `get_config()`).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          config: Model config dictionary.\n",
      " |          custom_objects: Optional dictionary mapping names\n",
      " |              (strings) to custom classes or functions to be\n",
      " |              considered during deserialization.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A model instance.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of improperly formatted config dict.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.network.Network:\n",
      " |  \n",
      " |  input_spec\n",
      " |      Gets the model's input specs.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of `InputSpec` instances (one per input to the model)\n",
      " |              or a single instance if the model has only one input.\n",
      " |  \n",
      " |  layers\n",
      " |  \n",
      " |  losses\n",
      " |      Retrieves the model's losses.\n",
      " |      \n",
      " |      Will only include losses that are either\n",
      " |      unconditional, or conditional on inputs to this model\n",
      " |      (e.g. will not include losses that depend on tensors\n",
      " |      that aren't inputs to this model).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of loss tensors.\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  state_updates\n",
      " |      Returns the `updates` from all layers that are stateful.\n",
      " |      \n",
      " |      This is useful for separating training updates and\n",
      " |      state updates, e.g. when we need to update a layer's internal state\n",
      " |      during prediction.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of update ops.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |      Retrieves the model's updates.\n",
      " |      \n",
      " |      Will only include updates that are either\n",
      " |      unconditional, or conditional on inputs to this model\n",
      " |      (e.g. will not include updates that depend on tensors\n",
      " |      that aren't inputs to this model).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of update ops.\n",
      " |  \n",
      " |  uses_learning_phase\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, **kwargs)\n",
      " |      Wrapper around self.call(), for handling internal references.\n",
      " |      \n",
      " |      If a Keras tensor is passed:\n",
      " |          - We call self._add_inbound_node().\n",
      " |          - If necessary, we `build` the layer to match\n",
      " |              the _keras_shape of the input(s).\n",
      " |          - We update the _keras_shape of every input tensor with\n",
      " |              its new shape (obtained via self.compute_output_shape).\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |          - We update the _keras_history of the output tensor(s)\n",
      " |              with the current layer.\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Can be a tensor or list/tuple of tensors.\n",
      " |          **kwargs: Additional keyword arguments to be passed to `call()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output of the layer's `call` method.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case the layer is missing shape information\n",
      " |              for its `build` call.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Adds losses to the layer.\n",
      " |      \n",
      " |      The loss may potentially be conditional on some inputs tensors,\n",
      " |      for instance activity losses are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          losses: loss tensor or list of loss tensors\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the losses as conditional on these inputs.\n",
      " |              If None is passed, the loss is assumed unconditional\n",
      " |              (e.g. L2 weight regularization, which only depends\n",
      " |              on the layer's weights variables, not on any inputs tensors).\n",
      " |  \n",
      " |  add_metric(self, value, name=None)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          value: Metric tensor.\n",
      " |          name: String metric name.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Adds updates to the layer.\n",
      " |      \n",
      " |      The updates may potentially be conditional on some inputs tensors,\n",
      " |      for instance batch norm updates are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          updates: update op or list of update ops\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the updates as conditional on these inputs.\n",
      " |              If None is passed, the updates are assumed unconditional.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=True, constraint=None)\n",
      " |      Adds a weight variable to the layer.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, the name for the weight variable.\n",
      " |          shape: The shape tuple of the weight.\n",
      " |          dtype: The dtype of the weight.\n",
      " |          initializer: An Initializer instance (callable).\n",
      " |          regularizer: An optional Regularizer instance.\n",
      " |          trainable: A boolean, whether the weight should\n",
      " |              be trained via backprop or not (assuming\n",
      " |              that the layer itself is also trainable).\n",
      " |          constraint: An optional Constraint instance.\n",
      " |      \n",
      " |      # Returns\n",
      " |          The created weight variable.\n",
      " |  \n",
      " |  assert_input_compatibility(self, inputs)\n",
      " |      Checks compatibility between the layer and provided inputs.\n",
      " |      \n",
      " |      This checks that the tensor(s) `input`\n",
      " |      verify the input assumptions of the layer\n",
      " |      (if any). If not, exceptions are raised.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case of mismatch between\n",
      " |              the provided inputs and the expectations of the layer.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the layer weights.\n",
      " |      \n",
      " |      Must be implemented on all layers that have weights.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Keras tensor (future input to layer)\n",
      " |              or list/tuple of Keras tensors to reference\n",
      " |              for weight shape computations.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Counts the total number of scalars composing the weights.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An integer count.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the layer isn't yet built\n",
      " |              (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  built\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input shape tuple\n",
      " |          (or list of input shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output tensor or list of output tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one inbound node,\n",
      " |      or if all inbound nodes have the same output shape.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output shape tuple\n",
      " |          (or list of input shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  weights\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'model_2/Encoder-12-FeedForward-Norm/add_1:0' shape=(None, None, 768) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##留个问题以后想：就是经过padding之后，需要不需要输入mask矩阵，如果需要该如何输入\n",
    "# input_ids = tf.constant([[31, 51, 99], [15, 5, 0]])\n",
    "# input_mask = tf.constant([[1, 1, 1], [1, 1, 0]])\n",
    "# token_type_ids = tf.Variable([[0, 0, 1], [0, 2, 0]])\n",
    "\n",
    "\n",
    "# x1_input=[input_ids,token_type_ids]\n",
    "\n",
    "# print(x1_input)\n",
    "# # x2_input=None\n",
    "\n",
    "# bert_model([x1_input,x2_input])\n",
    "\n",
    "# # import tensorflow as tf\n",
    "# # x_indices=[[1,2,3,0,0],[10,8,0,0,0]]\n",
    "# # x_segments=[[0,0,0,0,0],[0,0,0,0,0]]\n",
    "# # x_masks=[[1,1,1,0,0],[[1,1,0,0,0]]]\n",
    "# # yy=[[0],[1]]\n",
    "# # input_data=tf.constant([x_indices,x_segments])\n",
    "# # print(input_data.shape)\n",
    "# # x_temp = bert_model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [3, 4, 5]] \n",
      " [9999]\n"
     ]
    }
   ],
   "source": [
    "[xx,yy]=[[1,2,3],[3,4,5]],[9999]\n",
    "print(xx,'\\n',yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'lambda_1/strided_slice:0' shape=(None, 768) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##这里的x是bert的output即self.sequence_output = self.all_encoder_layers[-1]\n",
    "\n",
    "x = Lambda(lambda x: x[:, 0])(x)## 取出[CLS]对应的向量用来做分类\n",
    "x#shape=(None, 768) =（batch_size,hidden_size)seq取第一个\n",
    "####这个可以用于分类代表一句话的语义\n",
    "#但是不能用于QA因为QA需要seq中每个token的语义，帮助判断是否为答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 4)\n",
      "[[[ 1  2  3  4]\n",
      "  [ 5  6  7  8]\n",
      "  [ 9 10 11 12]]\n",
      "\n",
      " [[ 4  3  2  1]\n",
      "  [ 8  7  6  5]\n",
      "  [12 11 10  9]]] \n",
      "\n",
      "[[1 2 3 4]\n",
      " [4 3 2 1]] \n",
      "\n",
      "[[[1 2 3 4]]\n",
      "\n",
      " [[4 3 2 1]]] \n",
      "\n",
      "[[1 2 3 4]\n",
      " [4 3 2 1]]\n"
     ]
    }
   ],
   "source": [
    "dd=np.array([\n",
    "    [[1,2,3,4],[5,6,7,8],[9,10,11,12]],\n",
    "     [[4,3,2,1],[8,7,6,5],[12,11,10,9]],\n",
    "])\n",
    "#(batch_size,seq_length,hidden_size)=(2,3,4)\n",
    "print(dd.shape)\n",
    "print(dd,'\\n')\n",
    "print(dd[:,0],'\\n')##确实取了seq_0对应的向量#shape=(2,4)##理解成(2,3*4);前面的2都用到，3*4的二维矩阵只取第0行（所有列）\n",
    "print(dd[:, 0:1, :],'\\n')#shape=(2,1,4)\n",
    "print(np.squeeze(dd[:, 0:1, :], axis=1))#squeeze之后变成和前面一样的了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [4, 3, 2, 1]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, None, 768)    101677056   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 768)          0           model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            769         lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 101,677,825\n",
      "Trainable params: 101,677,825\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "p = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model([x1_in, x2_in], p)\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(1e-5), # 用足够小的学习率\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132392.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "101677056/768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4137.25"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "132392./32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_D = data_generator(train_data)\n",
    "valid_D = data_generator(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([array([[ 101,  704, 1744, ...,    0,    0,    0],\n",
      "       [ 101, 2791, 7313, ...,    0,    0,    0],\n",
      "       [ 101, 5632,  794, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [ 101, 1146,  775, ...,    0,    0,    0],\n",
      "       [ 101, 3683,  704, ...,    0,    0,    0],\n",
      "       [ 101,  122,  119, ..., 3683, 1071,  102]]), array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]])], array([[0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1]]))\n",
      "(32, 1)\n"
     ]
    }
   ],
   "source": [
    "for index, each in enumerate(valid_D):\n",
    "    if index>0:\n",
    "        break\n",
    "    print(each)\n",
    "#     print(each[0])\n",
    "    print(np.array(each[1]).shape)\n",
    "#     each[0],'\\n',each[1]\n",
    "#     print(each[0],'\\n',each[1],'\\n',each[2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 11/594 [..............................] - ETA: 1:03:26 - loss: 0.6002 - accuracy: 0.6989"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-cad151504170>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.fit_generator(\n",
    "    train_D.__iter__(),\n",
    "    steps_per_epoch=len(train_D),\n",
    "    epochs=5,\n",
    "    validation_data=valid_D.__iter__(),\n",
    "    validation_steps=len(valid_D)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, None, 768)    101677056   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 768)          0           model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            769         lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 101,677,825\n",
      "Trainable params: 101,677,825\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddd=model.get_layer('lambda_1').output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 768)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ddd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-eee051e58740>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mddd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "ddd[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 768)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddd[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddd[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7399683 ],\n",
       "       [0.8641331 ],\n",
       "       [0.32531452],\n",
       "       [0.37061012],\n",
       "       [0.62136763],\n",
       "       [0.6888844 ],\n",
       "       [0.7299098 ],\n",
       "       [0.868304  ],\n",
       "       [0.14410311],\n",
       "       [0.8372526 ],\n",
       "       [0.34206262],\n",
       "       [0.2529854 ],\n",
       "       [0.92776513],\n",
       "       [0.3182729 ],\n",
       "       [0.30037963],\n",
       "       [0.42912117],\n",
       "       [0.89562416],\n",
       "       [0.59108394],\n",
       "       [0.73442155],\n",
       "       [0.16221812],\n",
       "       [0.93979126],\n",
       "       [0.28815824],\n",
       "       [0.8344465 ],\n",
       "       [0.5298022 ],\n",
       "       [0.4722598 ],\n",
       "       [0.25225955],\n",
       "       [0.86818075],\n",
       "       [0.7982975 ],\n",
       "       [0.90290093],\n",
       "       [0.46055615],\n",
       "       [0.3619317 ],\n",
       "       [0.31031817],\n",
       "       [0.8076936 ],\n",
       "       [0.8234111 ],\n",
       "       [0.51733804],\n",
       "       [0.8359425 ],\n",
       "       [0.3521155 ],\n",
       "       [0.17739475],\n",
       "       [0.6987046 ],\n",
       "       [0.33018547],\n",
       "       [0.91324604],\n",
       "       [0.86131847],\n",
       "       [0.72156215],\n",
       "       [0.9291462 ],\n",
       "       [0.34599152],\n",
       "       [0.12644461],\n",
       "       [0.71060646],\n",
       "       [0.8610461 ],\n",
       "       [0.7204146 ],\n",
       "       [0.19134957],\n",
       "       [0.83792555],\n",
       "       [0.4158178 ],\n",
       "       [0.24509096],\n",
       "       [0.26707786],\n",
       "       [0.25605294],\n",
       "       [0.8658907 ],\n",
       "       [0.31086832],\n",
       "       [0.9272566 ],\n",
       "       [0.72350276],\n",
       "       [0.7839334 ],\n",
       "       [0.8090477 ],\n",
       "       [0.10431913],\n",
       "       [0.13262787],\n",
       "       [0.8585557 ],\n",
       "       [0.43810695],\n",
       "       [0.63479966],\n",
       "       [0.29707682],\n",
       "       [0.37570927],\n",
       "       [0.44016218],\n",
       "       [0.41398847],\n",
       "       [0.3587703 ],\n",
       "       [0.4073952 ],\n",
       "       [0.19000712],\n",
       "       [0.17816365],\n",
       "       [0.8659799 ],\n",
       "       [0.86906624],\n",
       "       [0.1750499 ],\n",
       "       [0.8186078 ],\n",
       "       [0.40740067],\n",
       "       [0.3812756 ],\n",
       "       [0.48131046],\n",
       "       [0.1819782 ],\n",
       "       [0.25978878],\n",
       "       [0.6536685 ],\n",
       "       [0.6708987 ],\n",
       "       [0.85030377],\n",
       "       [0.69772786],\n",
       "       [0.76313573],\n",
       "       [0.66524893],\n",
       "       [0.9420942 ],\n",
       "       [0.4340201 ],\n",
       "       [0.39004833],\n",
       "       [0.74737155],\n",
       "       [0.68562686],\n",
       "       [0.14442593],\n",
       "       [0.7943463 ],\n",
       "       [0.8949845 ],\n",
       "       [0.34764332],\n",
       "       [0.5047974 ],\n",
       "       [0.78411627],\n",
       "       [0.43692893],\n",
       "       [0.94458264],\n",
       "       [0.9211277 ],\n",
       "       [0.4508692 ],\n",
       "       [0.88224566],\n",
       "       [0.4651131 ],\n",
       "       [0.37923762],\n",
       "       [0.6859356 ],\n",
       "       [0.2645983 ],\n",
       "       [0.8037319 ],\n",
       "       [0.2263934 ],\n",
       "       [0.59593844],\n",
       "       [0.8527616 ],\n",
       "       [0.80848676],\n",
       "       [0.44392493],\n",
       "       [0.6989217 ],\n",
       "       [0.424487  ],\n",
       "       [0.37068713],\n",
       "       [0.749029  ],\n",
       "       [0.15720117],\n",
       "       [0.6819498 ],\n",
       "       [0.52084774],\n",
       "       [0.7069444 ],\n",
       "       [0.11232871],\n",
       "       [0.78699684],\n",
       "       [0.16527674],\n",
       "       [0.83081967],\n",
       "       [0.9103329 ],\n",
       "       [0.22691125],\n",
       "       [0.8831773 ],\n",
       "       [0.7245024 ],\n",
       "       [0.74400467],\n",
       "       [0.16738182],\n",
       "       [0.610943  ],\n",
       "       [0.65153086],\n",
       "       [0.38845956],\n",
       "       [0.8943856 ],\n",
       "       [0.1982787 ],\n",
       "       [0.82778406],\n",
       "       [0.30899683],\n",
       "       [0.85135466],\n",
       "       [0.29868144],\n",
       "       [0.75797284],\n",
       "       [0.83930314],\n",
       "       [0.55757755],\n",
       "       [0.83602965],\n",
       "       [0.5884348 ],\n",
       "       [0.76620674],\n",
       "       [0.30918583],\n",
       "       [0.06612816],\n",
       "       [0.79579604],\n",
       "       [0.7210956 ],\n",
       "       [0.89561045],\n",
       "       [0.7966808 ],\n",
       "       [0.19795021],\n",
       "       [0.9042647 ],\n",
       "       [0.45350826],\n",
       "       [0.47880632],\n",
       "       [0.3499748 ],\n",
       "       [0.90005684],\n",
       "       [0.5916115 ],\n",
       "       [0.23160344],\n",
       "       [0.7099455 ],\n",
       "       [0.4263302 ],\n",
       "       [0.6464459 ],\n",
       "       [0.79084957],\n",
       "       [0.30398875],\n",
       "       [0.3523615 ],\n",
       "       [0.9088261 ],\n",
       "       [0.37170267],\n",
       "       [0.76869136],\n",
       "       [0.8787474 ],\n",
       "       [0.33519912],\n",
       "       [0.75646937],\n",
       "       [0.5490023 ],\n",
       "       [0.10116231],\n",
       "       [0.93435085],\n",
       "       [0.8113665 ],\n",
       "       [0.7168066 ],\n",
       "       [0.6595131 ],\n",
       "       [0.16577595],\n",
       "       [0.8389782 ],\n",
       "       [0.31528363],\n",
       "       [0.2781538 ],\n",
       "       [0.81003606],\n",
       "       [0.48323494],\n",
       "       [0.3437521 ],\n",
       "       [0.8170832 ],\n",
       "       [0.42236942],\n",
       "       [0.4568708 ],\n",
       "       [0.70434237],\n",
       "       [0.3401925 ],\n",
       "       [0.8158493 ],\n",
       "       [0.12673256],\n",
       "       [0.7384064 ],\n",
       "       [0.7481078 ],\n",
       "       [0.19065347],\n",
       "       [0.86738026],\n",
       "       [0.89303464],\n",
       "       [0.849743  ],\n",
       "       [0.73862696],\n",
       "       [0.6684837 ],\n",
       "       [0.39796165],\n",
       "       [0.5464415 ],\n",
       "       [0.8671682 ],\n",
       "       [0.84962106],\n",
       "       [0.67478377],\n",
       "       [0.51733804],\n",
       "       [0.36479118],\n",
       "       [0.90236217],\n",
       "       [0.8475255 ],\n",
       "       [0.59806687],\n",
       "       [0.698513  ],\n",
       "       [0.0460377 ],\n",
       "       [0.15872008],\n",
       "       [0.16671559],\n",
       "       [0.79528576],\n",
       "       [0.8837129 ],\n",
       "       [0.377449  ],\n",
       "       [0.5729482 ],\n",
       "       [0.28436428],\n",
       "       [0.16612548],\n",
       "       [0.7564658 ],\n",
       "       [0.2974406 ],\n",
       "       [0.8603343 ],\n",
       "       [0.47209486],\n",
       "       [0.63985324],\n",
       "       [0.75491107],\n",
       "       [0.22862488],\n",
       "       [0.17712513],\n",
       "       [0.637255  ],\n",
       "       [0.15020978],\n",
       "       [0.29974774],\n",
       "       [0.28125066],\n",
       "       [0.85010815],\n",
       "       [0.50059175],\n",
       "       [0.32842898],\n",
       "       [0.815617  ],\n",
       "       [0.13076332],\n",
       "       [0.22326282],\n",
       "       [0.48323494],\n",
       "       [0.632206  ],\n",
       "       [0.3873909 ],\n",
       "       [0.37097082],\n",
       "       [0.45959434],\n",
       "       [0.6404425 ],\n",
       "       [0.20541143],\n",
       "       [0.7096695 ],\n",
       "       [0.44048512],\n",
       "       [0.38650057],\n",
       "       [0.81465065],\n",
       "       [0.62700444],\n",
       "       [0.6907386 ],\n",
       "       [0.5147011 ],\n",
       "       [0.3235213 ],\n",
       "       [0.74953115],\n",
       "       [0.8437393 ],\n",
       "       [0.378256  ],\n",
       "       [0.22722286],\n",
       "       [0.20365581],\n",
       "       [0.37790573],\n",
       "       [0.1549896 ],\n",
       "       [0.553905  ],\n",
       "       [0.41441834],\n",
       "       [0.8877133 ],\n",
       "       [0.8714917 ],\n",
       "       [0.8663399 ],\n",
       "       [0.69826835],\n",
       "       [0.74063975],\n",
       "       [0.6016979 ],\n",
       "       [0.8826116 ],\n",
       "       [0.71410793],\n",
       "       [0.5905462 ],\n",
       "       [0.8086729 ],\n",
       "       [0.43456256],\n",
       "       [0.7298536 ],\n",
       "       [0.94935656],\n",
       "       [0.2823463 ],\n",
       "       [0.71799713],\n",
       "       [0.89913666],\n",
       "       [0.7802513 ],\n",
       "       [0.7887491 ],\n",
       "       [0.79264766],\n",
       "       [0.7754562 ],\n",
       "       [0.32249594],\n",
       "       [0.91847676],\n",
       "       [0.6727924 ],\n",
       "       [0.8516855 ],\n",
       "       [0.07239157],\n",
       "       [0.7216629 ],\n",
       "       [0.43280238],\n",
       "       [0.84898525],\n",
       "       [0.8550186 ],\n",
       "       [0.2753275 ],\n",
       "       [0.81189907],\n",
       "       [0.85330176],\n",
       "       [0.15599763],\n",
       "       [0.4788683 ],\n",
       "       [0.64281595],\n",
       "       [0.78459966],\n",
       "       [0.7727021 ],\n",
       "       [0.5353518 ],\n",
       "       [0.24135584],\n",
       "       [0.8847034 ],\n",
       "       [0.61082345],\n",
       "       [0.2610444 ],\n",
       "       [0.8210025 ],\n",
       "       [0.754153  ],\n",
       "       [0.23341182],\n",
       "       [0.9124934 ],\n",
       "       [0.76316965],\n",
       "       [0.88155615],\n",
       "       [0.1071834 ],\n",
       "       [0.6352887 ],\n",
       "       [0.45664436],\n",
       "       [0.835086  ],\n",
       "       [0.14555088],\n",
       "       [0.53736717],\n",
       "       [0.6658953 ],\n",
       "       [0.4470874 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_generator(valid_D.__iter__(),steps=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
